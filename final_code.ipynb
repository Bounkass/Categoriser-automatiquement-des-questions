{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#114b98\">      <div align=\"center\">             Catégoriser automatiquement des questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GZ-0_iKb-2sm"
   },
   "outputs": [],
   "source": [
    "#python librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ast import literal_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importation et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bHbmg2pn_KB2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Title  \\\n",
      "0  [bracket, print, array, comma]   \n",
      "1         [c, listing, directory]   \n",
      "2  [return, datatables, wcf, net]   \n",
      "\n",
      "                                                Body                     Tags  \\\n",
      "0  [slash, program, original, output, letter, por...   [java, array, android]   \n",
      "1  [file, directory, cross, folder, c, scan, plat...                [file, c]   \n",
      "2  [close, datatables, behaviorcontracts, datatab...  [web, service, c#, net]   \n",
      "\n",
      "                                           text_comb  \n",
      "0  [slash, program, original, output, letter, por...  \n",
      "1  [cross, directory, file, folder, listing, c, s...  \n",
      "2  [close, datatables, behaviorcontracts, datatab...  \n",
      "Number of Tags: 50\n"
     ]
    }
   ],
   "source": [
    "#Import the cleaned dataset\n",
    "\n",
    "path =\"C:/Users/moumouni/Desktop/OC_P5_mlbis/Stack_questions_cleaned.csv\"\n",
    "data = pd.read_csv(path,sep=';')\n",
    "for col in ['Title', 'Body', 'Tags', 'text_comb']:\n",
    "     data[col] = data[col].apply(literal_eval) \n",
    "     \n",
    "print(data.head(3))\n",
    "\n",
    "# transform target tags\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(data.Tags)\n",
    "y_mlb = mlb.transform(data.Tags)\n",
    "print(\"Number of Tags:\", len(mlb.classes_))\n",
    "#\n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.text_comb,\\\n",
    "                    y_mlb, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Piple of the final modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aETKsB9pLIdx",
    "outputId": "a920075e-244c-4469-b830-3fb4e4a6412f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score ROC_AUC: 0.966087207040356\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "# tfidf features\n",
    "final_model = Pipeline([('tfidf', TfidfVectorizer(analyzer=\"word\",\n",
    "                             max_df=.98,\n",
    "                             min_df= 2,\n",
    "                             tokenizer=None,\n",
    "                             preprocessor=' '.join,\n",
    "                             stop_words=None,\n",
    "                             lowercase=False)),\n",
    "                        ('lr', OneVsRestClassifier(LogisticRegression()))])\n",
    "\n",
    "#fit model\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "#prediction and score\n",
    "y_score = final_model.predict_proba(X_test)\n",
    "print('Score ROC_AUC:', metrics.roc_auc_score(y_test, y_score,multi_class=\"ovr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "\n",
    "#Modèle serialisation\n",
    "dump(final_model, open(\"final_model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with one text\n",
    "text = ['serialize','model','c#','class','data']\n",
    "#threshold for labels with scores, fitted from the ROC \n",
    "threshold = 0.11 \n",
    "y_pred = final_model.predict_proba(np.array([text,]))\n",
    "tag = mlb.inverse_transform((y_pred>threshold)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags proposés: [('c#', 'data', 'net', 'python')]\n"
     ]
    }
   ],
   "source": [
    "print('Tags proposés:', tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "final_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
